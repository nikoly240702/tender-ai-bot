#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª–∞–¥–∫–∏ "–î–æ–∫—É–º–µ–Ω—Ç—ã" –Ω–∞ zakupki.gov.ru.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

import requests
from bs4 import BeautifulSoup
import warnings
import re

warnings.filterwarnings('ignore')
try:
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except:
    pass


def check_documents_tab(tender_number, tender_type):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∫–ª–∞–¥–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

    tender_type: zk20 (223-–§–ó –∫–æ—Ç–∏—Ä–æ–≤–∫–∏), ea20 (—ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–µ –∞—É–∫—Ü–∏–æ–Ω—ã), etc.
    """

    # –§–æ—Ä–º–∏—Ä—É–µ–º URL –≤–∫–ª–∞–¥–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    docs_url = f"https://zakupki.gov.ru/epz/order/notice/{tender_type}/view/documents.html?regNumber={tender_number}"

    print(f"\n{'='*70}")
    print(f"–ü–†–û–í–ï–†–ö–ê –í–ö–õ–ê–î–ö–ò '–î–û–ö–£–ú–ï–ù–¢–´'")
    print(f"{'='*70}")
    print(f"–¢–µ–Ω–¥–µ—Ä: {tender_number}")
    print(f"URL: {docs_url}\n")

    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    })

    try:
        response = session.get(docs_url, timeout=30, verify=False)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')

        # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        print("üìÑ –ù–ê–ô–î–ï–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´:\n")

        doc_links = []

        # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
        all_links = soup.find_all('a', href=True)

        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            if any(ext in href.lower() for ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.rtf']):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã
                if 'zakupki-traffic' not in href and 'cookie' not in href.lower():
                    doc_links.append({
                        'href': href,
                        'text': text,
                        'type': 'file'
                    })
                    print(f"   ‚úÖ {text}")
                    print(f"      URL: {href}")
                    print()

        # –ú–µ—Ç–æ–¥ 2: –ò—â–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É zakupki.gov.ru
        doc_containers = soup.find_all(['div', 'table'],
                                       class_=lambda x: x and ('document' in str(x).lower() or 'attach' in str(x).lower()))

        print(f"\n{'‚îÄ'*70}")
        print(f"üì¶ –ö–û–ù–¢–ï–ô–ù–ï–†–´ –î–û–ö–£–ú–ï–ù–¢–û–í: {len(doc_containers)}\n")

        for i, container in enumerate(doc_containers[:5], 1):
            print(f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {i}:")
            print(f"   Tag: {container.name}")
            print(f"   Class: {container.get('class')}")

            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            links = container.find_all('a', href=True)
            if links:
                print(f"   –°—Å—ã–ª–æ–∫ –≤–Ω—É—Ç—Ä–∏: {len(links)}")
                for link in links[:3]:
                    print(f"      - {link.get_text(strip=True)}: {link.get('href')[:60]}...")
            print()

        # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ç–∞–±–ª–∏—Ü —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        print(f"\n{'‚îÄ'*70}")
        print("üìã –¢–ê–ë–õ–ò–¶–´ –° –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò:\n")

        tables = soup.find_all('table')
        for i, table in enumerate(tables, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
            table_links = table.find_all('a', href=True)
            file_links = [l for l in table_links if any(ext in l.get('href', '').lower()
                         for ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx'])]

            if file_links:
                print(f"–¢–∞–±–ª–∏—Ü–∞ {i} (—Å–æ–¥–µ—Ä–∂–∏—Ç {len(file_links)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤):")
                for link in file_links[:5]:
                    text = link.get_text(strip=True)
                    href = link.get('href')
                    print(f"   - {text}")
                    print(f"     {href}")
                print()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        print(f"\n{'‚îÄ'*70}")
        print("üîê –ü–†–û–í–ï–†–ö–ê –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–ò:\n")

        auth_indicators = [
            '–∞–≤—Ç–æ—Ä–∏–∑', '–≤–æ–π—Ç–∏', '–≤—Ö–æ–¥', 'login', 'auth',
            '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä', '–ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç', '–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω'
        ]

        page_text = soup.get_text().lower()
        auth_required = any(indicator in page_text for indicator in auth_indicators)

        if auth_required:
            print("   ‚ö†Ô∏è  –í–æ–∑–º–æ–∂–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
            # –ò—â–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            for indicator in auth_indicators:
                if indicator in page_text:
                    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    idx = page_text.find(indicator)
                    context = page_text[max(0, idx-50):min(len(page_text), idx+50)]
                    print(f"      –ù–∞–π–¥–µ–Ω–æ: '{indicator}' - –∫–æ–Ω—Ç–µ–∫—Å—Ç: ...{context}...")
        else:
            print("   ‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML
        debug_file = Path(__file__).parent / 'output' / f'debug_documents_tab_{tender_number}.html'
        debug_file.parent.mkdir(parents=True, exist_ok=True)

        with open(debug_file, 'w', encoding='utf-8') as f:
            f.write(soup.prettify())

        print(f"\n{'='*70}")
        print(f"üíæ HTML —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {debug_file}")
        print(f"{'='*70}\n")

        return doc_links

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return []


def main():
    print("\n" + "="*70)
    print("  –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ê –ö –í–ö–õ–ê–î–ö–ï '–î–û–ö–£–ú–ï–ù–¢–´'")
    print("="*70 + "\n")

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–∞—Ö —Ç–µ–Ω–¥–µ—Ä–æ–≤
    test_cases = [
        ("0322200027425000278", "zk20"),  # –ó–∞–ø—Ä–æ—Å –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ 223-–§–ó
        ("0352100025025000104", "ea20"),  # –≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π –∞—É–∫—Ü–∏–æ–Ω
    ]

    for tender_number, tender_type in test_cases:
        doc_links = check_documents_tab(tender_number, tender_type)

        if doc_links:
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(doc_links)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è")
        else:
            print(f"\n‚ö†Ô∏è  –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            print(f"üí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print(f"   - –î–æ–∫—É–º–µ–Ω—Ç—ã –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∑–∞–∫–∞–∑—á–∏–∫–æ–º")
            print(f"   - –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ zakupki.gov.ru")
            print(f"   - –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ")

        print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    main()
