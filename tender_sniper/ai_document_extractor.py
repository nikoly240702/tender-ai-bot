"""
AI Document Extractor - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç GPT-4o-mini –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ PDF/DOCX —Ñ–∞–π–ª–æ–≤.
PREMIUM —Ñ—É–Ω–∫—Ü–∏—è - –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è Premium –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: flat schema + multi-pass extraction + chunking + validation + red flags.
"""

import asyncio
import json
import logging
import os
import re
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta

from tender_sniper.ai_features import AIFeatureGate, format_ai_feature_locked_message

logger = logging.getLogger(__name__)

# –ú–µ—Å—è—Ü—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç
_MONTHS_RU = {
    '—è–Ω–≤–∞—Ä—è': '01', '—Ñ–µ–≤—Ä–∞–ª—è': '02', '–º–∞—Ä—Ç–∞': '03', '–∞–ø—Ä–µ–ª—è': '04',
    '–º–∞—è': '05', '–∏—é–Ω—è': '06', '–∏—é–ª—è': '07', '–∞–≤–≥—É—Å—Ç–∞': '08',
    '—Å–µ–Ω—Ç—è–±—Ä—è': '09', '–æ–∫—Ç—è–±—Ä—è': '10', '–Ω–æ—è–±—Ä—è': '11', '–¥–µ–∫–∞–±—Ä—è': '12',
    '—è–Ω–≤–∞—Ä—å': '01', '—Ñ–µ–≤—Ä–∞–ª—å': '02', '–º–∞—Ä—Ç': '03', '–∞–ø—Ä–µ–ª—å': '04',
    '–º–∞–π': '05', '–∏—é–Ω—å': '06', '–∏—é–ª—å': '07', '–∞–≤–≥—É—Å—Ç': '08',
    '—Å–µ–Ω—Ç—è–±—Ä—å': '09', '–æ–∫—Ç—è–±—Ä—å': '10', '–Ω–æ—è–±—Ä—å': '11', '–¥–µ–∫–∞–±—Ä—å': '12',
}


class TenderDocumentExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

    Multi-pass –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - Pass 1: –°—Ä–æ–∫–∏ –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞ (submission_deadline, execution_deadline, delivery_address)
    - Pass 2: –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è (advance, payment, security, guarantee)
    - Pass 3: –ü–æ–∑–∏—Ü–∏–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (items, licenses, experience, summary)
    """

    MODEL = "gpt-4o-mini"
    CHUNK_MAX_CHARS = 25000
    CHUNK_OVERLAP = 2000
    MAX_CHUNKS = 3  # Limit chunks to avoid rate limits
    RETRY_ATTEMPTS = 3
    RETRY_BASE_DELAY = 2.0  # seconds

    # --- Pass 1: –°—Ä–æ–∫–∏ –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞ ---
    PROMPT_DATES = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≥–æ—Å–∑–∞–∫—É–ø–æ–∫ –†–æ—Å—Å–∏–∏.

–ò–∑–≤–ª–µ–∫–∏ –¢–û–õ–¨–ö–û —Å—Ä–æ–∫–∏ –∏ –∞–¥—Ä–µ—Å –ø–æ—Å—Ç–∞–≤–∫–∏. –û—Ç–≤–µ—Ç –°–¢–†–û–ì–û –≤ JSON:

{
    "submission_deadline": "–¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–æ–∫, —Ñ–æ—Ä–º–∞—Ç –î–î.–ú–ú.–ì–ì–ì–ì –ß–ß:–ú–ú –ú–°–ö. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "execution_deadline": "—Å—Ä–æ–∫ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è/–ø–æ—Å—Ç–∞–≤–∫–∏ –î–û–°–õ–û–í–ù–û –∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: '10 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π —Å –º–æ–º–µ–Ω—Ç–∞ –∑–∞–∫–ª—é—á–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞'. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "delivery_address": "–∞–¥—Ä–µ—Å –ü–û–°–¢–ê–í–ö–ò (–ù–ï —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å –∑–∞–∫–∞–∑—á–∏–∫–∞!). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'"
}

–ü–†–ê–í–ò–õ–ê:
1. submission_deadline ‚Äî –∏—â–∏ "–æ–∫–æ–Ω—á–∞–Ω–∏–µ –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–æ–∫", "–¥–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å—Ä–æ–∫–∞ –ø–æ–¥–∞—á–∏", "–∑–∞—è–≤–∫–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è –¥–æ"
2. execution_deadline ‚Äî –∏—â–∏ "—Å—Ä–æ–∫ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è", "—Å—Ä–æ–∫ –ø–æ—Å—Ç–∞–≤–∫–∏", "—Å—Ä–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç", –ø–∏—à–∏ –î–û–°–õ–û–í–ù–û
3. delivery_address ‚Äî –∏—â–∏ "–º–µ—Å—Ç–æ –ø–æ—Å—Ç–∞–≤–∫–∏", "–∞–¥—Ä–µ—Å –¥–æ—Å—Ç–∞–≤–∫–∏", "–º–µ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç"
4. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî –ø–∏—à–∏ "–ù–µ —É–∫–∞–∑–∞–Ω–æ"

"""

    # --- Pass 2: –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è ---
    PROMPT_FINANCE = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≥–æ—Å–∑–∞–∫—É–ø–æ–∫ –†–æ—Å—Å–∏–∏.

–ò–∑–≤–ª–µ–∫–∏ –¢–û–õ–¨–ö–û —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è. –û—Ç–≤–µ—Ç –°–¢–†–û–ì–û –≤ JSON:

{
    "advance_percent": "—Ä–∞–∑–º–µ—Ä –∞–≤–∞–Ω—Å–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä '30%'. –ï—Å–ª–∏ –∞–≤–∞–Ω—Å –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω ‚Äî '–ù–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω'. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "payment_deadline": "—Å—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä '15 —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π –ø–æ—Å–ª–µ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –∞–∫—Ç–∞'. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "application_security": "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä '1% –æ—Ç –ù–ú–¶–ö' –∏–ª–∏ '50 000 —Ä—É–±.' –∏–ª–∏ '–ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è'. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "contract_security": "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä '5% –æ—Ç –ù–ú–¶–ö' –∏–ª–∏ '100 000 —Ä—É–±.'. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "bank_guarantee_allowed": "–¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –ª–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è: '–î–∞', '–ù–µ—Ç' –∏–ª–∏ '–ù–µ —É–∫–∞–∑–∞–Ω–æ'"
}

–ü–†–ê–í–ò–õ–ê:
1. –ò—â–∏ "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏", "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞", "–±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è"
2. –ò—â–∏ "–∞–≤–∞–Ω—Å", "–∞–≤–∞–Ω—Å–æ–≤—ã–π –ø–ª–∞—Ç—ë–∂", "–ø—Ä–µ–¥–æ–ø–ª–∞—Ç–∞"
3. –ò—â–∏ "–æ–ø–ª–∞—Ç–∞", "—Ä–∞—Å—á—ë—Ç", "—Å—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã"
4. –£–∫–∞–∑—ã–≤–∞–π –ø—Ä–æ—Ü–µ–Ω—Ç—ã —Å —Å–∏–º–≤–æ–ª–æ–º %, —Å—É–º–º—ã —Å "—Ä—É–±."

"""

    # --- Pass 3: –ü–æ–∑–∏—Ü–∏–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è ---
    PROMPT_ITEMS = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≥–æ—Å–∑–∞–∫—É–ø–æ–∫ –†–æ—Å—Å–∏–∏.

–ò–∑–≤–ª–µ–∫–∏ –ø–æ–∑–∏—Ü–∏–∏ –∑–∞–∫—É–ø–∫–∏ –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫—É. –û—Ç–≤–µ—Ç –°–¢–†–û–ì–û –≤ JSON:

{
    "items_count": "—á–∏—Å–ª–æ –ø–æ–∑–∏—Ü–∏–π/–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –≤ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä '3'. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!",
    "items_description": "–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–∑–∏—Ü–∏–π –í –û–î–ù–£ –°–¢–†–û–ö–£. –§–æ—Ä–º–∞—Ç: '1. –ù–∞–∑–≤–∞–Ω–∏–µ (–∫–æ–ª-–≤–æ) ‚Äî –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä-–∫–∏; 2. –ù–∞–∑–≤–∞–Ω–∏–µ (–∫–æ–ª-–≤–æ) ‚Äî —Ö–∞—Ä-–∫–∏'. –ú–∞–∫—Å–∏–º—É–º 10 –ø–æ–∑–∏—Ü–∏–π. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!",
    "licenses_required": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ª–∏—Ü–µ–Ω–∑–∏–∏: '–õ–∏—Ü–µ–Ω–∑–∏—è –§–°–ë', '–õ–∏—Ü–µ–Ω–∑–∏—è –§–°–¢–≠–ö', '–°–†–û' –∏ —Ç.–ø. –ï—Å–ª–∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è ‚Äî '–ù–µ —Ç—Ä–µ–±—É—é—Ç—Å—è'",
    "experience_required": "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–ø—ã—Ç—É, –Ω–∞–ø—Ä–∏–º–µ—Ä '–ù–µ –º–µ–Ω–µ–µ 3 –ª–µ—Ç –≤ —Å—Ñ–µ—Ä–µ IT'. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî '–ù–µ —É–∫–∞–∑–∞–Ω–æ'",
    "summary": "1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: —á—Ç–æ –∑–∞–∫—É–ø–∞—é—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –∫–ª—é—á–µ–≤—ã–µ —É—Å–ª–æ–≤–∏—è"
}

–ü–†–ê–í–ò–õ–ê:
1. items_count ‚Äî –í–°–ï–ì–î–ê –∑–∞–ø–æ–ª–Ω–∏! –ü–æ—Å—á–∏—Ç–∞–π –ø–æ–∑–∏—Ü–∏–∏ –≤ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏/–¢–ó
2. items_description ‚Äî –∏–∑–≤–ª–µ–∫–∏ –í–°–ï –ø–æ–∑–∏—Ü–∏–∏ (–º–∞–∫—Å 10), –¥–ª—è –∫–∞–∂–¥–æ–π: –Ω–∞–∑–≤–∞–Ω–∏–µ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä-–∫–∏. –§–æ—Ä–º–∞—Ç –ù–£–ú–ï–†–û–í–ê–ù–ù–û–ì–û –°–ü–ò–°–ö–ê –í –û–î–ù–£ –°–¢–†–û–ö–£ —á–µ—Ä–µ–∑ "; "
3. –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –±—Ä–µ–Ω–¥/–º–∞—Ä–∫–∞/–º–æ–¥–µ–ª—å ‚Äî –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–∫–ª—é—á–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
4. licenses_required ‚Äî –¢–û–õ–¨–ö–û –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ (–§–°–ë, –§–°–¢–≠–ö, –ú–ß–°, –°–†–û), –ù–ï –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã
5. summary ‚Äî –∫—Ä–∞—Ç–∫–æ, 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è

"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self._client = None

    @property
    def client(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞."""
        if self._client is None:
            try:
                from openai import AsyncOpenAI
                self._client = AsyncOpenAI(api_key=self.api_key)
            except ImportError:
                logger.warning("OpenAI –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                return None
        return self._client

    def _build_context(self, tender_info: Optional[Dict[str, Any]]) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ tender_info."""
        if not tender_info:
            return ""
        parts = []
        if tender_info.get('number'):
            parts.append(f"–ù–æ–º–µ—Ä –∑–∞–∫—É–ø–∫–∏: {tender_info['number']}")
        if tender_info.get('price'):
            parts.append(f"–ù–ú–¶: {tender_info['price']:,.0f} —Ä—É–±.")
        if tender_info.get('customer'):
            parts.append(f"–ó–∞–∫–∞–∑—á–∏–∫: {tender_info['customer']}")
        if parts:
            return "–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –¢–ï–ù–î–ï–†–ï:\n" + "\n".join(parts) + "\n\n"
        return ""

    def _chunk_text(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ chunks —Å overlap –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
        –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –º–∞–∫—Å–∏–º—É–º MAX_CHUNKS —á–∞–Ω–∫–æ–≤ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è rate limits."""
        max_chars = self.CHUNK_MAX_CHARS
        overlap = self.CHUNK_OVERLAP

        if len(text) <= max_chars:
            return [text]

        # –î–ª—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚Äî —É–º–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –ø–µ—Ä–µ–¥ chunking
        max_total = max_chars * self.MAX_CHUNKS
        if len(text) > max_total:
            # –ë–µ—Ä—ë–º –Ω–∞—á–∞–ª–æ (–æ—Å–Ω–æ–≤–Ω—ã–µ —É—Å–ª–æ–≤–∏—è) + –∫–æ–Ω–µ—Ü (–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è–º–∏)
            head_size = max_total * 2 // 3
            tail_size = max_total - head_size
            text = text[:head_size] + "\n\n[...]\n\n" + text[-tail_size:]
            logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ (head={head_size}, tail={tail_size})")

        chunks = []
        start = 0
        while start < len(text):
            end = start + max_chars

            if end >= len(text):
                chunks.append(text[start:])
                break

            # –ò—â–µ–º –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –±–ª–∏–∂–µ –∫ –≥—Ä–∞–Ω–∏—Ü–µ
            search_zone = text[end - 500:end]
            last_dot = search_zone.rfind('.')
            if last_dot != -1:
                end = end - 500 + last_dot + 1
            else:
                # –ò—â–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
                last_nl = search_zone.rfind('\n')
                if last_nl != -1:
                    end = end - 500 + last_nl + 1

            chunks.append(text[start:end])
            start = end - overlap

            if len(chunks) >= self.MAX_CHUNKS:
                break

        logger.info(f"–¢–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} chunk(s), overlap={overlap}")
        return chunks

    async def _extract_pass(
        self,
        text: str,
        prompt: str,
        context: str,
        max_tokens: int = 500
    ) -> Dict[str, Any]:
        """–û–¥–∏–Ω pass –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ API —Å retry –Ω–∞ 429."""
        for attempt in range(self.RETRY_ATTEMPTS):
            try:
                response = await self.client.chat.completions.create(
                    model=self.MODEL,
                    messages=[
                        {"role": "user", "content": prompt + context + "–î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –¢–ï–ù–î–ï–†–ê:\n" + text}
                    ],
                    max_tokens=max_tokens,
                    temperature=0.1,
                    response_format={"type": "json_object"}
                )
                result_text = response.choices[0].message.content.strip()
                return json.loads(result_text)
            except json.JSONDecodeError as e:
                logger.error(f"JSON parse error in pass: {e}")
                return {}
            except Exception as e:
                error_str = str(e)
                if '429' in error_str and attempt < self.RETRY_ATTEMPTS - 1:
                    delay = self.RETRY_BASE_DELAY * (2 ** attempt)
                    logger.warning(f"Rate limit hit, retry {attempt + 1}/{self.RETRY_ATTEMPTS} in {delay}s")
                    await asyncio.sleep(delay)
                    continue
                logger.error(f"API error in pass (attempt {attempt + 1}): {e}")
                return {}
        return {}

    def _merge_chunk_results(self, all_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö chunks."""
        if not all_results:
            return {}
        if len(all_results) == 1:
            return all_results[0]

        # –ü–æ–ª—è, –≥–¥–µ –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        single_fields = [
            'submission_deadline', 'execution_deadline', 'delivery_address',
            'advance_percent', 'payment_deadline', 'application_security',
            'contract_security', 'bank_guarantee_allowed',
            'licenses_required', 'experience_required', 'summary',
        ]

        final = {}
        for field in single_fields:
            for result in all_results:
                val = result.get(field)
                if val and str(val).strip() and str(val).strip() != '–ù–µ —É–∫–∞–∑–∞–Ω–æ':
                    final[field] = val
                    break
            if field not in final:
                # –ë–µ—Ä—ë–º —Ö–æ—Ç—è –±—ã "–ù–µ —É–∫–∞–∑–∞–Ω–æ" –µ—Å–ª–∏ –µ—Å—Ç—å
                for result in all_results:
                    if field in result:
                        final[field] = result[field]
                        break

        # items_description ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏–∑ –≤—Å–µ—Ö chunks
        items_parts = []
        for result in all_results:
            desc = result.get('items_description', '')
            if desc and str(desc).strip() and str(desc) != '–ù–µ —É–∫–∞–∑–∞–Ω–æ':
                items_parts.append(str(desc))
        if items_parts:
            final['items_description'] = '; '.join(items_parts)
        elif 'items_description' not in final:
            final['items_description'] = '–ù–µ —É–∫–∞–∑–∞–Ω–æ'

        # items_count ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        max_count = 0
        for result in all_results:
            try:
                count = int(result.get('items_count', 0))
                max_count = max(max_count, count)
            except (ValueError, TypeError):
                pass
        final['items_count'] = str(max_count) if max_count > 0 else '–ù–µ —É–∫–∞–∑–∞–Ω–æ'

        return final

    def _validate_and_normalize(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        # –í—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–ª—è
        expected_fields = [
            'submission_deadline', 'execution_deadline', 'delivery_address',
            'items_count', 'items_description',
            'licenses_required', 'experience_required',
            'advance_percent', 'payment_deadline',
            'application_security', 'contract_security', 'bank_guarantee_allowed',
            'summary',
        ]

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç—ã–µ –ø–æ–ª—è
        for field in expected_fields:
            if field not in data or not str(data[field]).strip():
                data[field] = '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç: "20 —Ñ–µ–≤—Ä–∞–ª—è 2026" ‚Üí "20.02.2026"
        for date_field in ['submission_deadline']:
            val = str(data.get(date_field, ''))
            normalized = _normalize_date_text(val)
            if normalized != val:
                data[date_field] = normalized

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è items_count ‚Äî –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–∏—Å–ª–æ
        try:
            count = int(data.get('items_count', 0))
            data['items_count'] = str(count)
        except (ValueError, TypeError):
            # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å –µ—Å–ª–∏ –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è
            pass

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è bank_guarantee_allowed
        bg = str(data.get('bank_guarantee_allowed', '')).lower()
        if bg in ('–¥–∞', 'true', '–¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è', '—Ä–∞–∑—Ä–µ—à–µ–Ω–∞'):
            data['bank_guarantee_allowed'] = '–î–∞'
        elif bg in ('–Ω–µ—Ç', 'false', '–Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è'):
            data['bank_guarantee_allowed'] = '–ù–µ—Ç'

        return data

    def _extract_red_flags(self, data: Dict[str, Any]) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫—Ä–∞—Å–Ω—ã–µ –∏ –∂—ë–ª—Ç—ã–µ —Ñ–ª–∞–≥–∏ –∏–∑ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        flags = []

        # –õ–∏—Ü–µ–Ω–∑–∏–∏ –§–°–ë/–§–°–¢–≠–ö ‚Äî –∫—Ä–∞—Å–Ω—ã–π —Ñ–ª–∞–≥
        licenses = str(data.get('licenses_required', '')).lower()
        if '—Ñ—Å–±' in licenses:
            flags.append('–¢—Ä–µ–±—É–µ—Ç—Å—è –ª–∏—Ü–µ–Ω–∑–∏—è –§–°–ë')
        if '—Ñ—Å—Ç—ç–∫' in licenses:
            flags.append('–¢—Ä–µ–±—É–µ—Ç—Å—è –ª–∏—Ü–µ–Ω–∑–∏—è –§–°–¢–≠–ö')
        if '—Å—Ä–æ' in licenses:
            flags.append('–¢—Ä–µ–±—É–µ—Ç—Å—è —á–ª–µ–Ω—Å—Ç–≤–æ –≤ –°–†–û')

        # –í—ã—Å–æ–∫–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ
        for field_name, label in [
            ('application_security', '–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏'),
            ('contract_security', '–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞'),
        ]:
            val = str(data.get(field_name, ''))
            pct_match = re.search(r'(\d+(?:[.,]\d+)?)\s*%', val)
            if pct_match:
                try:
                    pct = float(pct_match.group(1).replace(',', '.'))
                    if pct > 5:
                        flags.append(f'–í—ã—Å–æ–∫–æ–µ {label}: {val}')
                except (ValueError, TypeError):
                    pass

        # –ö–æ—Ä–æ—Ç–∫–∏–π —Å—Ä–æ–∫ –ø–æ–¥–∞—á–∏
        submission = str(data.get('submission_deadline', ''))
        deadline_date = _parse_date(submission)
        if deadline_date:
            days_left = (deadline_date - datetime.now()).days
            if days_left < 0:
                flags.append('–°—Ä–æ–∫ –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–æ–∫ –∏—Å—Ç—ë–∫!')
            elif days_left < 3:
                flags.append(f'–°—Ä–æ–∫ –ø–æ–¥–∞—á–∏ < 3 –¥–Ω–µ–π!')
            elif days_left < 7:
                flags.append(f'–°—Ä–æ–∫ –ø–æ–¥–∞—á–∏ < 7 –¥–Ω–µ–π')

        return flags

    async def extract_from_text(
        self,
        document_text: str,
        subscription_tier: str = 'trial',
        tender_info: Optional[Dict[str, Any]] = None
    ) -> Tuple[Dict[str, Any], bool]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.
        Multi-pass: 3 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –∫–∞–∂–¥—ã–π chunk.

        Returns:
            Tuple[Dict, bool]: (–∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, is_ai_extracted)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Premium –¥–æ—Å—Ç—É–ø
        gate = AIFeatureGate(subscription_tier)
        if not gate.can_use('summarization'):
            return ({
                'error': 'premium_required',
                'message': format_ai_feature_locked_message('summarization')
            }, False)

        if not self.api_key or not self.client:
            logger.warning("OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return (self._create_fallback_extraction(document_text, tender_info), False)

        context = self._build_context(tender_info)
        chunks = self._chunk_text(document_text)

        try:
            all_results = []
            passes = [
                (self.PROMPT_DATES, 500),
                (self.PROMPT_FINANCE, 500),
                (self.PROMPT_ITEMS, 2000),
            ]
            for chunk_idx, chunk in enumerate(chunks):
                merged = {}
                # Run passes sequentially to avoid rate limit bursts
                for prompt, max_tok in passes:
                    result = await self._extract_pass(chunk, prompt, context, max_tokens=max_tok)
                    if isinstance(result, dict):
                        merged.update(result)
                all_results.append(merged)

            final = self._merge_chunk_results(all_results)
            final = self._validate_and_normalize(final)
            final['red_flags'] = self._extract_red_flags(final)
            final['_meta'] = {
                'extracted_at': datetime.now().isoformat(),
                'source': 'ai',
                'model': self.MODEL,
                'input_chars': len(document_text),
                'chunks': len(chunks),
                'passes': 3,
            }
            logger.info(
                f"AI-–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(document_text)} —Å–∏–º–≤–æ–ª–æ–≤, "
                f"{len(chunks)} chunk(s), {len(final.get('red_flags', []))} red flags"
            )
            return (final, True)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ AI-–∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return (self._create_fallback_extraction(document_text, tender_info), False)

    def _create_fallback_extraction(
        self,
        document_text: str,
        tender_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞—ë—Ç –±–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–µ–∑ AI (regex-based fallback) –≤ flat —Ñ–æ—Ä–º–∞—Ç–µ."""
        text_lower = document_text.lower()

        result = {
            'submission_deadline': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
            'execution_deadline': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
            'delivery_address': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
            'items_count': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
            'items_description': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å',
            'licenses_required': '–ù–µ —Ç—Ä–µ–±—É—é—Ç—Å—è',
            'experience_required': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'advance_percent': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'payment_deadline': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'application_security': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'contract_security': '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'bank_guarantee_allowed': '–î–∞' if '–±–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è' in text_lower else '–ù–µ —É–∫–∞–∑–∞–Ω–æ',
            'summary': '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.',
            'red_flags': [],
            '_meta': {
                'extracted_at': datetime.now().isoformat(),
                'source': 'fallback',
                'input_chars': len(document_text),
            }
        }

        # –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏
        m = re.search(r'–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∑–∞—è–≤–∫–∏[:\s]+(\d+(?:[.,]\d+)?)\s*%', text_lower)
        if m:
            result['application_security'] = f"{m.group(1).replace(',', '.')}% –æ—Ç –ù–ú–¶–ö"

        # –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
        m = re.search(r'–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ (?:–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è )?–∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞[:\s]+(\d+(?:[.,]\d+)?)\s*%', text_lower)
        if m:
            result['contract_security'] = f"{m.group(1).replace(',', '.')}% –æ—Ç –ù–ú–¶–ö"

        # –°—Ä–æ–∫–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
        for pattern in [
            r'—Å—Ä–æ–∫ (?:–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è|–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è|–ø–æ—Å—Ç–∞–≤–∫–∏)[:\s]+(\d+)\s*(–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω\w+|—Ä–∞–±–æ—á–∏—Ö)?\s*–¥–Ω',
            r'–≤ —Ç–µ—á–µ–Ω–∏–µ\s+(\d+)\s*(–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω\w+|—Ä–∞–±–æ—á–∏—Ö)?\s*–¥–Ω',
        ]:
            m = re.search(pattern, text_lower)
            if m:
                days = m.group(1)
                day_type = m.group(2) or '–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö'
                result['execution_deadline'] = f"{days} {day_type} –¥–Ω–µ–π"
                break

        # –õ–∏—Ü–µ–Ω–∑–∏–∏
        found_licenses = []
        license_patterns = [
            ('–ª–∏—Ü–µ–Ω–∑–∏—è —Ñ—Å–±', '–õ–∏—Ü–µ–Ω–∑–∏—è –§–°–ë'),
            ('–ª–∏—Ü–µ–Ω–∑–∏—è —Ñ—Å—Ç—ç–∫', '–õ–∏—Ü–µ–Ω–∑–∏—è –§–°–¢–≠–ö'),
            ('–ª–∏—Ü–µ–Ω–∑–∏—è –º—á—Å', '–õ–∏—Ü–µ–Ω–∑–∏—è –ú–ß–°'),
            ('–ª–∏—Ü–µ–Ω–∑–∏—è –º–∏–Ω–∑–¥—Ä–∞–≤', '–õ–∏—Ü–µ–Ω–∑–∏—è –ú–∏–Ω–∑–¥—Ä–∞–≤'),
            ('–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è', '–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è'),
            ('—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è', '–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–∞—è –ª–∏—Ü–µ–Ω–∑–∏—è'),
        ]
        for pattern, name in license_patterns:
            if pattern in text_lower:
                found_licenses.append(name)
        if '—Å—Ä–æ' in text_lower or '—Å–∞–º–æ—Ä–µ–≥—É–ª–∏—Ä—É–µ–º–æ–π' in text_lower:
            found_licenses.append('–°–†–û')
        if found_licenses:
            result['licenses_required'] = ', '.join(found_licenses)

        # –û–ø—ã—Ç
        exp_match = re.search(
            r'–æ–ø—ã—Ç\w*\s+(?:—Ä–∞–±–æ—Ç—ã\s+)?(?:–Ω–µ\s+)?–º–µ–Ω–µ–µ\s+(\d+)\s*(?:–ª–µ—Ç|–≥–æ–¥–∞)',
            text_lower
        )
        if exp_match:
            result['experience_required'] = f"–ù–µ –º–µ–Ω–µ–µ {exp_match.group(1)} –ª–µ—Ç"

        # Red flags –∏–∑ fallback
        result['red_flags'] = self._extract_red_flags(result)

        return result

    async def extract_from_file(
        self,
        file_path: str,
        subscription_tier: str = 'trial',
        tender_info: Optional[Dict[str, Any]] = None
    ) -> Tuple[Dict[str, Any], bool]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Ñ–∞–π–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏."""
        try:
            from src.document_processor.text_extractor import TextExtractor

            result = TextExtractor.extract_text(file_path)
            document_text = result['text']

            if not document_text or document_text.startswith('[–ù–µ —É–¥–∞–ª–æ—Å—å'):
                return ({
                    'error': 'extraction_failed',
                    'message': f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞: {file_path}"
                }, False)

            return await self.extract_from_text(document_text, subscription_tier, tender_info)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return ({
                'error': 'file_error',
                'message': str(e)
            }, False)


# --- –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç ---

def _normalize_date_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –¥–∞—Ç—É: '20 —Ñ–µ–≤—Ä–∞–ª—è 2026' ‚Üí '20.02.2026'."""
    if not text or text in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
        return text

    # –ü–∞—Ç—Ç–µ—Ä–Ω: "20 —Ñ–µ–≤—Ä–∞–ª—è 2026" –∏–ª–∏ "20 —Ñ–µ–≤—Ä–∞–ª—è 2026 –≥."
    m = re.search(r'(\d{1,2})\s+([–∞-—è—ë]+)\s+(\d{4})', text)
    if m:
        day, month_name, year = m.group(1), m.group(2).lower(), m.group(3)
        month_num = _MONTHS_RU.get(month_name)
        if month_num:
            formatted = f"{int(day):02d}.{month_num}.{year}"
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è –µ—Å–ª–∏ –µ—Å—Ç—å
            time_match = re.search(r'(\d{1,2}:\d{2})', text)
            if time_match:
                formatted += f" {time_match.group(1)}"
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ú–°–ö –µ—Å–ª–∏ –µ—Å—Ç—å
            if '–º—Å–∫' in text.lower():
                formatted += " –ú–°–ö"
            return formatted

    return text


def _parse_date(text: str) -> Optional[datetime]:
    """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    if not text:
        return None

    # –î–î.–ú–ú.–ì–ì–ì–ì
    m = re.match(r'(\d{2})\.(\d{2})\.(\d{4})', text)
    if m:
        try:
            return datetime(int(m.group(3)), int(m.group(2)), int(m.group(1)))
        except ValueError:
            return None
    return None


# --- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Telegram ---

def format_extraction_for_telegram(extraction: Dict[str, Any], is_ai: bool) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ –Ω–æ–≤—ã–π flat-—Ñ–æ—Ä–º–∞—Ç, —Ç–∞–∫ –∏ —Å—Ç–∞—Ä—ã–π nested-—Ñ–æ—Ä–º–∞—Ç.
    """
    if extraction.get('error'):
        return extraction.get('message', '–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö')

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç: –µ—Å–ª–∏ –µ—Å—Ç—å execution_deadline (—Å—Ç—Ä–æ–∫–∞) ‚Äî –Ω–æ–≤—ã–π flat
    is_new_format = isinstance(extraction.get('execution_deadline'), str)

    if is_new_format:
        return _format_new_schema(extraction, is_ai)
    else:
        return _format_old_schema(extraction, is_ai)


def _classify_red_flag(flag: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–∫–æ–Ω–∫—É –¥–ª—è red flag: ‚õî –∫—Ä–∏—Ç–∏—á–Ω—ã–π –∏–ª–∏ ‚ö†Ô∏è –∂—ë–ª—Ç—ã–π."""
    flag_lower = flag.lower()
    critical_keywords = ['—Ñ—Å–±', '—Ñ—Å—Ç—ç–∫', '–∏—Å—Ç—ë–∫', '–∏—Å—Ç–µ–∫', '–º–µ–Ω–µ–µ 3 –¥–Ω–µ–π', '–º–µ–Ω–µ–µ 2 –¥–Ω–µ–π', '–º–µ–Ω–µ–µ 1 –¥–Ω—è', '1 –¥–µ–Ω—å', '2 –¥–Ω—è']
    for kw in critical_keywords:
        if kw in flag_lower:
            return '‚õî'
    return '‚ö†Ô∏è'


def _format_new_schema(extraction: Dict[str, Any], is_ai: bool) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ flat-—Ñ–æ—Ä–º–∞—Ç–∞."""
    lines = []

    if is_ai:
        lines.append("üîç <b>AI-–∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏</b>\n")
    else:
        lines.append("üìã <b>–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏</b>\n")

    # –ü–æ–¥–∞—á–∞ –∑–∞—è–≤–æ–∫
    submission = extraction.get('submission_deadline', '')
    if submission and submission not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
        lines.append(f"‚è∞ <b>–ü–æ–¥–∞—á–∞ –∑–∞—è–≤–æ–∫ –¥–æ:</b> {submission}")
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        lines.append("")

    # –¢–æ–≤–∞—Ä—ã/—Ä–∞–±–æ—Ç—ã
    items_desc = extraction.get('items_description', '')
    items_count = extraction.get('items_count', '')
    if items_desc and items_desc not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
        count_str = f" ({items_count} –Ω–∞–∏–º.)" if items_count and items_count not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å') else ""
        lines.append(f"üì¶ <b>–¢–æ–≤–∞—Ä—ã/—Ä–∞–±–æ—Ç—ã{count_str}:</b>")
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ "; N." –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
        items_lines = re.split(r';\s*(?=\d+\.)', items_desc)
        for item_line in items_lines[:10]:
            item_line = item_line.strip()
            if item_line:
                lines.append(f"‚Ä¢ {item_line}")
        lines.append("")

    # –°—Ä–æ–∫–∏
    exec_deadline = extraction.get('execution_deadline', '')
    delivery = extraction.get('delivery_address', '')
    has_deadlines = (exec_deadline and exec_deadline not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å')) or \
                    (delivery and delivery not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'))
    if has_deadlines:
        lines.append("üìÖ <b>–°—Ä–æ–∫–∏ –∏ –ª–æ–≥–∏—Å—Ç–∏–∫–∞:</b>")
        if exec_deadline and exec_deadline not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ: {exec_deadline[:120]}")
        if delivery and delivery not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ê–¥—Ä–µ—Å: {delivery[:120]}")
        lines.append("")

    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
    licenses = extraction.get('licenses_required', '')
    experience = extraction.get('experience_required', '')
    has_reqs = (licenses and licenses not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å', '–ù–µ —Ç—Ä–µ–±—É—é—Ç—Å—è')) or \
               (experience and experience not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'))
    if has_reqs:
        lines.append("‚ö†Ô∏è <b>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫—É:</b>")
        if licenses and licenses not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å', '–ù–µ —Ç—Ä–µ–±—É—é—Ç—Å—è'):
            lines.append(f"‚Ä¢ –õ–∏—Ü–µ–Ω–∑–∏–∏: {licenses}")
        if experience and experience not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –û–ø—ã—Ç: {experience}")
        lines.append("")

    # –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ
    app_sec = extraction.get('application_security', '')
    con_sec = extraction.get('contract_security', '')
    bg = extraction.get('bank_guarantee_allowed', '')
    has_security = (app_sec and app_sec not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å')) or \
                   (con_sec and con_sec not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'))
    if has_security:
        lines.append("üí≥ <b>–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ:</b>")
        if app_sec and app_sec not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ó–∞—è–≤–∫–∞: {app_sec}")
        if con_sec and con_sec not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ö–æ–Ω—Ç—Ä–∞–∫—Ç: {con_sec}")
        if bg and bg not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ë–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è: {bg}")
        lines.append("")

    # –û–ø–ª–∞—Ç–∞
    advance = extraction.get('advance_percent', '')
    pay_deadline = extraction.get('payment_deadline', '')
    has_payment = (advance and advance not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å')) or \
                  (pay_deadline and pay_deadline not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'))
    if has_payment:
        lines.append("üí∞ <b>–û–ø–ª–∞—Ç–∞:</b>")
        if advance and advance not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –ê–≤–∞–Ω—Å: {advance}")
        if pay_deadline and pay_deadline not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
            lines.append(f"‚Ä¢ –°—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã: {pay_deadline}")
        lines.append("")

    # Red flags
    red_flags = extraction.get('red_flags', [])
    if red_flags:
        lines.append("üö© <b>–†–∏—Å–∫–∏:</b>")
        for flag in red_flags[:5]:
            icon = _classify_red_flag(flag)
            lines.append(f"‚Ä¢ {icon} {flag}")
        lines.append("")

    # –†–µ–∑—é–º–µ
    summary = extraction.get('summary', '')
    if summary and summary not in ('–ù–µ —É–∫–∞–∑–∞–Ω–æ', '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å'):
        lines.append(f"üìù <b>–†–µ–∑—é–º–µ:</b> {summary}")

    return "\n".join(lines)


def _format_old_schema(extraction: Dict[str, Any], is_ai: bool) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ nested-—Ñ–æ—Ä–º–∞—Ç–∞ (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)."""
    lines = []

    if is_ai:
        lines.append("üîç <b>AI-–∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏</b>\n")
    else:
        lines.append("üìã <b>–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏</b>\n")

    # –ü–ª–æ—â–∞–¥–∫–∞
    if extraction.get('trading_platform'):
        lines.append(f"‚Ä¢ <b>–ü–ª–æ—â–∞–¥–∫–∞:</b> {extraction['trading_platform']}")

    # –ü–æ–¥–∞—á–∞ –∑–∞—è–≤–æ–∫ (top-level)
    submission = extraction.get('submission_deadline')
    if submission:
        lines.append(f"‚è∞ <b>–ü–æ–¥–∞—á–∞ –∑–∞—è–≤–æ–∫ –¥–æ:</b> {submission}")

    if extraction.get('trading_platform') or submission:
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        lines.append("")

    # –¢–æ–≤–∞—Ä–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
    items = extraction.get('items', [])
    items_count = extraction.get('items_count')
    if not items:
        specs = extraction.get('technical_specs', {})
        items = specs.get('items_details', [])
        if not items_count:
            items_count = specs.get('items_count')

    if items:
        count_str = f" ({items_count} –Ω–∞–∏–º.)" if items_count else ""
        lines.append(f"üì¶ <b>–¢–æ–≤–∞—Ä—ã/—Ä–∞–±–æ—Ç—ã{count_str}:</b>")
        for item in items[:10]:
            name = item.get('name', '')
            qty = item.get('quantity', '')
            chars = item.get('characteristics', '')
            brand = item.get('brand')

            line_parts = [f"<b>{name}</b>"]
            if qty:
                line_parts.append(f"‚Äî {qty}")
            lines.append(f"‚Ä¢ {' '.join(line_parts)}")
            if chars:
                lines.append(f"    {chars[:150]}")
            if brand:
                lines.append(f"    –ë—Ä–µ–Ω–¥: {brand}")
        lines.append("")
    else:
        specs = extraction.get('technical_specs', {})
        if specs.get('main_items'):
            lines.append("üì¶ <b>–ü–æ–∑–∏—Ü–∏–∏:</b>")
            for item in specs['main_items'][:5]:
                lines.append(f"‚Ä¢ {item}")
            if specs.get('quantities'):
                lines.append(f"‚Ä¢ –ö–æ–ª-–≤–æ: {specs['quantities']}")
            lines.append("")

    # –°—Ä–æ–∫–∏
    deadlines = extraction.get('deadlines', {})
    if not submission:
        submission = deadlines.get('submission_deadline')
    has_deadlines = any([
        deadlines.get('execution_days'),
        deadlines.get('execution_description'),
        deadlines.get('delivery_address'),
    ])
    if has_deadlines:
        lines.append("üìÖ <b>–°—Ä–æ–∫–∏ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è:</b>")
        if deadlines.get('execution_days'):
            lines.append(f"‚Ä¢ –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ: {deadlines['execution_days']} –¥–Ω–µ–π")
        if deadlines.get('execution_description'):
            lines.append(f"‚Ä¢ {deadlines['execution_description'][:100]}")
        if deadlines.get('delivery_address'):
            lines.append(f"‚Ä¢ –ê–¥—Ä–µ—Å –ø–æ—Å—Ç–∞–≤–∫–∏: {deadlines['delivery_address'][:120]}")
        if not extraction.get('submission_deadline') and deadlines.get('submission_deadline'):
            lines.append(f"‚Ä¢ –ü–æ–¥–∞—á–∞ –∑–∞—è–≤–æ–∫ –¥–æ: <b>{deadlines['submission_deadline']}</b>")
        lines.append("")

    # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
    req = extraction.get('requirements', {})
    if any([req.get('licenses'), req.get('experience_years'), req.get('sro_required')]):
        lines.append("‚ö†Ô∏è <b>–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É—á–∞—Å—Ç–Ω–∏–∫—É:</b>")
        if req.get('licenses'):
            lines.append(f"‚Ä¢ –õ–∏—Ü–µ–Ω–∑–∏–∏: {', '.join(req['licenses'])}")
        if req.get('experience_years'):
            lines.append(f"‚Ä¢ –û–ø—ã—Ç: –æ—Ç {req['experience_years']} –ª–µ—Ç")
        if req.get('sro_required'):
            lines.append("‚Ä¢ –ß–ª–µ–Ω—Å—Ç–≤–æ –≤ –°–†–û: —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        lines.append("")

    # –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ
    sec = extraction.get('contract_security', {})
    if any([sec.get('application_security_percent'), sec.get('contract_security_percent')]):
        lines.append("üí≥ <b>–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ:</b>")
        if sec.get('application_security_percent'):
            lines.append(f"‚Ä¢ –ó–∞—è–≤–∫–∞: {sec['application_security_percent']}%")
        if sec.get('contract_security_percent'):
            lines.append(f"‚Ä¢ –ö–æ–Ω—Ç—Ä–∞–∫—Ç: {sec['contract_security_percent']}%")
        if sec.get('bank_guarantee_allowed'):
            lines.append("‚Ä¢ –ë–∞–Ω–∫–æ–≤—Å–∫–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è: –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è")
        lines.append("")

    # –û–ø–ª–∞—Ç–∞
    pay = extraction.get('payment_terms', {})
    if any([pay.get('advance_percent'), pay.get('payment_deadline_days')]):
        lines.append("üí∞ <b>–û–ø–ª–∞—Ç–∞:</b>")
        if pay.get('advance_percent'):
            lines.append(f"‚Ä¢ –ê–≤–∞–Ω—Å: {pay['advance_percent']}%")
        if pay.get('payment_deadline_days'):
            lines.append(f"‚Ä¢ –°—Ä–æ–∫ –æ–ø–ª–∞—Ç—ã: {pay['payment_deadline_days']} –¥–Ω–µ–π")
        lines.append("")

    # –†–∏—Å–∫–∏
    risks = extraction.get('risks', [])
    if risks:
        lines.append("üö© <b>–†–∏—Å–∫–∏:</b>")
        for risk in risks[:5]:
            icon = _classify_red_flag(risk)
            lines.append(f"‚Ä¢ {icon} {risk}")
        lines.append("")

    # –†–µ–∑—é–º–µ
    if extraction.get('summary'):
        lines.append(f"üìù <b>–†–µ–∑—é–º–µ:</b> {extraction['summary']}")

    return "\n".join(lines)


# Singleton instance
_extractor_instance: Optional[TenderDocumentExtractor] = None


def get_document_extractor() -> TenderDocumentExtractor:
    """–ü–æ–ª—É—á–∏—Ç—å singleton —ç–∫–∑–µ–º–ø–ª—è—Ä —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞."""
    global _extractor_instance
    if _extractor_instance is None:
        _extractor_instance = TenderDocumentExtractor()
    return _extractor_instance


async def extract_tender_documentation(
    document_text: str,
    subscription_tier: str = 'trial',
    tender_info: Optional[Dict[str, Any]] = None
) -> Tuple[Dict[str, Any], bool]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

    Returns:
        Tuple[Dict, bool]: (–¥–∞–Ω–Ω—ã–µ, is_ai_extracted)
    """
    extractor = get_document_extractor()
    return await extractor.extract_from_text(document_text, subscription_tier, tender_info)
