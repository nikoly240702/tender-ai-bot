"""
–ü–∞—Ä—Å–µ—Ä RSS-—Ñ–∏–¥–æ–≤ zakupki.gov.ru.
–≠—Ç–æ –õ–ï–ì–ê–õ–¨–ù–´–ô –∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–µ–Ω–¥–µ—Ä–∞—Ö.
"""

import feedparser
import requests
from typing import List, Dict, Any, Optional
from datetime import datetime
from urllib.parse import urlencode, quote_plus
import re
import warnings
import os

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL (–¥–ª—è zakupki.gov.ru)
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
try:
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except:
    pass


class ZakupkiRSSParser:
    """–ü–∞—Ä—Å–µ—Ä RSS-—Ñ–∏–¥–æ–≤ –¥–ª—è zakupki.gov.ru."""

    BASE_URL = "https://zakupki.gov.ru"
    RSS_BASE = f"{BASE_URL}/epz/order/extendedsearch/rss.html"

    def __init__(self, timeout: int = 60):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RSS –ø–∞—Ä—Å–µ—Ä–∞.

        Args:
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        self.timeout = timeout
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        proxy_url = os.getenv('PROXY_URL', '').strip()
        if proxy_url:
            self.session.proxies = {
                'http': proxy_url,
                'https': proxy_url
            }
            print(f"üîê RSS –ø–∞—Ä—Å–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ–∫—Å–∏: {proxy_url.split('@')[-1] if '@' in proxy_url else proxy_url}")

        # –ü–æ–ª–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ SSL verify –¥–ª—è –ø—Ä–æ–∫—Å–∏
        self.session.verify = False

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SSL –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
        import ssl
        from requests.adapters import HTTPAdapter
        from urllib3.util.ssl_ import create_urllib3_context
        from urllib3.util.retry import Retry

        class SSLAdapter(HTTPAdapter):
            """HTTPAdapter —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π SSL."""
            def init_poolmanager(self, *args, **kwargs):
                context = create_urllib3_context()
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                context.options |= 0x4  # OP_LEGACY_SERVER_CONNECT
                kwargs['ssl_context'] = context
                return super().init_poolmanager(*args, **kwargs)

        retry_strategy = Retry(
            total=3,
            backoff_factor=2,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        adapter = SSLAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def search_tenders_rss(
        self,
        keywords: Optional[str] = None,
        price_min: Optional[int] = None,
        price_max: Optional[int] = None,
        max_results: int = 50,
        regions: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        –ò—â–µ—Ç —Ç–µ–Ω–¥–µ—Ä—ã —á–µ—Ä–µ–∑ RSS-—Ñ–∏–¥ zakupki.gov.ru.

        Args:
            keywords: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            price_min: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ (—Ä—É–±)
            price_max: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ (—Ä—É–±)
            max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            regions: –°–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ—Ä–æ–≤
        """
        print(f"üì° –ü–æ–ª—É—á–µ–Ω–∏–µ RSS-—Ñ–∏–¥–∞ –æ—Ç zakupki.gov.ru...")

        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL RSS-—Ñ–∏–¥–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            rss_url = self._build_rss_url(
                keywords=keywords,
                price_min=price_min,
                price_max=price_max,
                regions=regions
            )

            print(f"   RSS URL: {rss_url[:100]}...")

            # –ü–æ–ª—É—á–∞–µ–º RSS —á–µ—Ä–µ–∑ requests (–æ–±—Ö–æ–¥–∏–º SSL –ø—Ä–æ–±–ª–µ–º—É)
            try:
                response = self.session.get(rss_url, timeout=self.timeout, verify=False)
                response.raise_for_status()
                rss_content = response.content
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS —á–µ—Ä–µ–∑ requests: {e}")
                # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ feedparser –Ω–∞–ø—Ä—è–º—É—é
                rss_content = rss_url

            # –ü–∞—Ä—Å–∏–º RSS
            feed = feedparser.parse(rss_content)

            if feed.bozo and not feed.entries:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS: {feed.bozo_exception}")

            tenders = []
            for entry in feed.entries[:max_results]:
                tender = self._parse_rss_entry(entry)
                if tender:
                    tenders.append(tender)

            print(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –∏–∑ RSS: {len(tenders)}")
            return tenders

        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è RSS: {e}")
            return []

    def _build_rss_url(
        self,
        keywords: Optional[str],
        price_min: Optional[int],
        price_max: Optional[int],
        regions: Optional[List[str]] = None
    ) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç URL –¥–ª—è RSS-—Ñ–∏–¥–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ–∏—Å–∫–∞."""
        params = {
            'morphology': 'on',
            'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
            'sortDirection': 'false',
            'sortBy': 'UPDATE_DATE',
            'fz44': 'on',  # 44-–§–ó
            'fz223': 'on',  # 223-–§–ó
            'af': 'on',  # –í—Å–µ —ç—Ç–∞–ø—ã
            'currencyIdGeneral': '-1'
        }

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—Ä–µ–≥–∏–æ–Ω—ã –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤ –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É)
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if keywords:
            params['searchString'] = keywords

        # –¶–µ–Ω–æ–≤–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
        if price_min:
            params['priceFromGeneral'] = str(price_min)
        if price_max:
            params['priceToGeneral'] = str(price_max)

        # –§–æ—Ä–º–∏—Ä—É–µ–º query string —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        query_string = urlencode(params, quote_via=quote_plus)
        return f"{self.RSS_BASE}?{query_string}"

    def _parse_rss_entry(self, entry) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É –∑–∞–ø–∏—Å—å –∏–∑ RSS-—Ñ–∏–¥–∞."""
        try:
            tender = {
                'name': entry.get('title', ''),
                'url': entry.get('link', ''),
                'published': entry.get('published', ''),
                'summary': entry.get('summary', ''),
            }

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ URL –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            tender['number'] = self._extract_number(entry.get('link', ''))

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
            price = self._extract_price_from_summary(entry.get('summary', ''))
            if price:
                tender['price'] = price
                tender['price_formatted'] = f"{price:,.2f} ‚ÇΩ"

            # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
            if entry.get('published_parsed'):
                tender['published_datetime'] = datetime(*entry.published_parsed[:6])

            return tender if tender.get('name') else None

        except Exception as e:
            print(f"   –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS entry: {e}")
            return None

    def _extract_number(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä —Ç–µ–Ω–¥–µ—Ä–∞ –∏–∑ URL."""
        match = re.search(r'regNumber=([A-Z0-9]+)', url)
        if match:
            return match.group(1)
        return ""

    def _extract_price_from_summary(self, summary: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è RSS."""
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ü–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ
        patterns = [
            r'–ù–ú–¶–ö[:\s]+([0-9\s,\.]+)',
            r'—Ü–µ–Ω[–∞-—è]*[:\s]+([0-9\s,\.]+)',
            r'—Å—É–º–º[–∞-—è]*[:\s]+([0-9\s,\.]+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, summary, re.IGNORECASE)
            if match:
                price_text = match.group(1)
                try:
                    cleaned = re.sub(r'[^\d,.]', '', price_text)
                    cleaned = cleaned.replace(',', '.')
                    return float(cleaned)
                except:
                    continue

        return None

    def get_tender_categories_rss(self) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è RSS –ø–æ–¥–ø–∏—Å–æ–∫.

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        """
        return [
            "–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            "–æ—Ñ–∏—Å–Ω–∞—è —Ç–µ—Ö–Ω–∏–∫–∞",
            "–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ",
            "—Å–µ—Ä–≤–µ—Ä–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            "—Å–µ—Ç–µ–≤–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            "–æ—Ä–≥—Ç–µ—Ö–Ω–∏–∫–∞",
            "–∫–∞–Ω—Ü–µ–ª—è—Ä—Å–∫–∏–µ —Ç–æ–≤–∞—Ä—ã",
            "–º–µ–±–µ–ª—å",
            "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
            "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç—ã"
        ]


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RSS –ø–∞—Ä—Å–µ—Ä–∞."""
    parser = ZakupkiRSSParser()

    # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ RSS
    print("\n" + "="*70)
    print("–¢–ï–°–¢ RSS –ü–ê–†–°–ï–†–ê ZAKUPKI.GOV.RU")
    print("="*70)

    tenders = parser.search_tenders_rss(
        keywords="–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ",
        price_min=500000,
        price_max=5000000,
        max_results=10
    )

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤: {len(tenders)}\n")

    for i, tender in enumerate(tenders[:5], 1):
        print(f"{i}. {tender.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:80]}")
        print(f"   –ù–æ–º–µ—Ä: {tender.get('number', 'N/A')}")
        if tender.get('price'):
            print(f"   –¶–µ–Ω–∞: {tender.get('price_formatted', 'N/A')}")
        print(f"   URL: {tender.get('url', 'N/A')}")
        print(f"   –î–∞—Ç–∞: {tender.get('published', 'N/A')}")
        print()


if __name__ == "__main__":
    main()
