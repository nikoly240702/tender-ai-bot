"""
–¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É "Atlas Copco".
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—á–µ–º—É RSS –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

from src.parsers.zakupki_rss_parser import ZakupkiRSSParser
import requests
from urllib.parse import urlencode, quote_plus

def test_direct_url():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä—è–º–æ–π URL RSS."""
    print("="*80)
    print("–¢–ï–°–¢ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä—è–º–æ–≥–æ URL RSS")
    print("="*80)

    # –§–æ—Ä–º–∏—Ä—É–µ–º URL —Ç–æ—á–Ω–æ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ –∫–æ–¥–µ
    params = {
        'morphology': 'on',
        'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
        'sortDirection': 'false',
        'sortBy': 'UPDATE_DATE',
        'fz44': 'on',
        'fz223': 'on',
        'af': 'on',
        'currencyIdGeneral': '-1',
        'searchString': 'Atlas copco',  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        'priceFromGeneral': '1000000',
        'priceToGeneral': '3000000'
    }

    query_string = urlencode(params, quote_via=quote_plus)
    rss_url = f"https://zakupki.gov.ru/epz/order/extendedsearch/rss.html?{query_string}"

    print(f"\nüì° URL: {rss_url}\n")

    try:
        response = requests.get(rss_url, timeout=30, verify=False)
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {response.status_code}")
        print(f"üìä –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response.content)} –±–∞–π—Ç")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        content = response.text

        if '<item>' in content:
            item_count = content.count('<item>')
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –≤ RSS: {item_count}")
        else:
            print("‚ö†Ô∏è  RSS –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–Ω–¥–µ—Ä–æ–≤ (<item> –Ω–µ –Ω–∞–π–¥–µ–Ω)")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫–∏
        if 'error' in content.lower() or '–æ—à–∏–±–∫–∞' in content.lower():
            print("‚ùå –í RSS –Ω–∞–π–¥–µ–Ω—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤
        print(f"\nüìÑ –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞:")
        print("-"*80)
        print(content[:500])
        print("-"*80)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def test_without_price_filter():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ü–µ–Ω–µ."""
    print("\n" + "="*80)
    print("–¢–ï–°–¢ 2: –ü–æ–∏—Å–∫ –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ü–µ–Ω–µ")
    print("="*80)

    params = {
        'morphology': 'on',
        'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
        'sortDirection': 'false',
        'sortBy': 'UPDATE_DATE',
        'fz44': 'on',
        'fz223': 'on',
        'af': 'on',
        'currencyIdGeneral': '-1',
        'searchString': 'Atlas copco'
    }

    query_string = urlencode(params, quote_via=quote_plus)
    rss_url = f"https://zakupki.gov.ru/epz/order/extendedsearch/rss.html?{query_string}"

    print(f"\nüì° URL: {rss_url}\n")

    try:
        response = requests.get(rss_url, timeout=30, verify=False)
        content = response.text

        if '<item>' in content:
            item_count = content.count('<item>')
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –≤ RSS: {item_count}")
        else:
            print("‚ö†Ô∏è  RSS –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–Ω–¥–µ—Ä–æ–≤")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def test_simplified_query():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å."""
    print("\n" + "="*80)
    print("–¢–ï–°–¢ 3: –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (—Ç–æ–ª—å–∫–æ '–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä')")
    print("="*80)

    params = {
        'morphology': 'on',
        'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
        'sortDirection': 'false',
        'sortBy': 'UPDATE_DATE',
        'fz44': 'on',
        'fz223': 'on',
        'af': 'on',
        'currencyIdGeneral': '-1',
        'searchString': '–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä'
    }

    query_string = urlencode(params, quote_via=quote_plus)
    rss_url = f"https://zakupki.gov.ru/epz/order/extendedsearch/rss.html?{query_string}"

    print(f"\nüì° URL: {rss_url}\n")

    try:
        response = requests.get(rss_url, timeout=30, verify=False)
        content = response.text

        if '<item>' in content:
            item_count = content.count('<item>')
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –≤ RSS: {item_count}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            import re
            titles = re.findall(r'<title>(.*?)</title>', content)
            if len(titles) > 1:  # –ü–µ—Ä–≤—ã–π title - —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–Ω–∞–ª–∞
                print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ—Ä–æ–≤:")
                for i, title in enumerate(titles[1:6], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∫–∞–Ω–∞–ª–∞
                    print(f"   {i}. {title}")
        else:
            print("‚ö†Ô∏è  RSS –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–Ω–¥–µ—Ä–æ–≤")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


def test_using_parser():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å –ø–∞—Ä—Å–µ—Ä–∞."""
    print("\n" + "="*80)
    print("–¢–ï–°–¢ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ZakupkiRSSParser")
    print("="*80)

    parser = ZakupkiRSSParser()

    # –¢–µ—Å—Ç 1: –° —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ –ø–æ —Ü–µ–Ω–µ
    print("\nüîç –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ —Ü–µ–Ω–µ (1-3 –º–ª–Ω):")
    tenders = parser.search_tenders_rss(
        keywords='Atlas copco',
        price_min=1000000,
        price_max=3000000,
        max_results=10
    )
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(tenders)} —Ç–µ–Ω–¥–µ—Ä–æ–≤")

    # –¢–µ—Å—Ç 2: –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ü–µ–Ω–µ
    print("\nüîç –ü–æ–∏—Å–∫ –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ —Ü–µ–Ω–µ:")
    tenders = parser.search_tenders_rss(
        keywords='Atlas copco',
        max_results=10
    )
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(tenders)} —Ç–µ–Ω–¥–µ—Ä–æ–≤")

    if tenders:
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ—Ä–æ–≤:")
        for i, tender in enumerate(tenders[:3], 1):
            print(f"   {i}. {tender.get('name', 'N/A')[:100]}")
            print(f"      –ù–æ–º–µ—Ä: {tender.get('number', 'N/A')}")
            print(f"      –¶–µ–Ω–∞: {tender.get('price_formatted', 'N/A')}")

    # –¢–µ—Å—Ç 3: –ü—Ä–æ—Å—Ç–æ "–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä"
    print("\nüîç –ü–æ–∏—Å–∫ '–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä' (–±–µ–∑ Atlas Copco):")
    tenders = parser.search_tenders_rss(
        keywords='–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä',
        max_results=10
    )
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(tenders)} —Ç–µ–Ω–¥–µ—Ä–æ–≤")


def test_web_interface():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ —Ç–µ–Ω–¥–µ—Ä—ã —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."""
    print("\n" + "="*80)
    print("–¢–ï–°–¢ 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (HTML)")
    print("="*80)

    # URL –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–Ω–µ RSS)
    params = {
        'morphology': 'on',
        'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
        'pageNumber': '1',
        'sortDirection': 'false',
        'recordsPerPage': '_10',
        'sortBy': 'UPDATE_DATE',
        'fz44': 'on',
        'fz223': 'on',
        'af': 'on',
        'currencyIdGeneral': '-1',
        'searchString': 'Atlas copco'
    }

    query_string = urlencode(params, quote_via=quote_plus)
    search_url = f"https://zakupki.gov.ru/epz/order/extendedsearch/results.html?{query_string}"

    print(f"\nüåê URL: {search_url}\n")

    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        }
        response = requests.get(search_url, headers=headers, timeout=30, verify=False)
        content = response.text

        print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {response.status_code}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        import re

        # –ò—â–µ–º "–ù–∞–π–¥–µ–Ω–æ X –∑–∞–ø–∏—Å–µ–π"
        match = re.search(r'–ù–∞–π–¥–µ–Ω–æ.*?(\d+).*?–∑–∞–ø–∏—Å', content, re.IGNORECASE)
        if match:
            count = match.group(1)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ–Ω–¥–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ –≤–µ–±: {count}")
        else:
            print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # –ò—â–µ–º –∑–∞–ø–∏—Å–∏ –æ —Ç–µ–Ω–¥–µ—Ä–∞—Ö
        if 'registry-entry__header-top__title' in content or 'search-registry-entry-block' in content:
            print("‚úÖ –í HTML –Ω–∞–π–¥–µ–Ω—ã –∑–∞–ø–∏—Å–∏ –æ —Ç–µ–Ω–¥–µ—Ä–∞—Ö")
        else:
            print("‚ö†Ô∏è  –í HTML –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∑–∞–ø–∏—Å–∏ –æ —Ç–µ–Ω–¥–µ—Ä–∞—Ö")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    import warnings
    warnings.filterwarnings('ignore')

    try:
        import urllib3
        urllib3.disable_warnings()
    except:
        pass

    print("\n" + "="*80)
    print("  –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–û–ò–°–ö–ê 'ATLAS COPCO' –ù–ê ZAKUPKI.GOV.RU")
    print("="*80)

    test_direct_url()
    test_without_price_filter()
    test_simplified_query()
    test_using_parser()
    test_web_interface()

    print("\n" + "="*80)
    print("  –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
    print("="*80)
